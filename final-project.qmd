---
title: "Final Project"
subtitle: "Data Science for Public Policy"
author: "Madeleine Adelson, Stephanie Jamilla, Jamie Jelly Murtha"
format: 
  html:
    code-line-numbers: true
    body-width: 1600px
embed-resources: true
editor_options: 
  chunk_output_type: console
execute: 
  warning: false
urlcolor: blue
toc: true
---

## About This Project
Climate Central's UHI index values (in Â°F) are "estimates of how much the urban built environment boosts temperatures. In other words, the UHI index is an estimate of the additional heat that local land use factors contribute to urban areas."

Stephanie 12/10 - We'll need to change the above blurb based on what temperature data we use


## Setup

Loading packages:
```{r}

library(dotenv)
library(tidyverse)
library(ggplot2)
library(sf)
library(tidycensus)
library(stringr)
library(jsonlite)
library(httr)
library(tidymodels)

# Clone the private github repository for this assignment using SSH link:
# git@github.com:stejamilla/final-project.git

# do not use scientific notation
options(scipen = 999)

```


# Exploring the Data

## Cleaning DC Land Cover Data
```{r}

# Read in Urban Tree Canopy by Census Block Group (2020) data from Open Data DC
# and clean up
landcover <- read_sf(paste0("data/Urban_Tree_Canopy",
                            "_by_Census_Block_Group_in_2020.shp")) |>
  rename(block_group = GEOID) |>
  # Drop other unrelated UHI index, which, here, measures average temperature
  # within each feature
  mutate(block_group = as.character(block_group)) |>
  rename_all(tolower) |>
  # remove columns that provide measures in acres, to focus instead on
  # percentage measures
  dplyr::select(-contains("_ac")) |>
  relocate(block_group, .after = objectid) |>
  # Converting UHI to Fahrenheit
  mutate(
    uhi = (uhi*(9/5) + 32)
  )

# Create key with Urban Tree Canopy data column descriptions and clean up
landcover_key <- read_csv("data/Urban_Tree_Canopy_Descriptions.csv",
                          col_names = FALSE) |>
  mutate(X1 = str_remove_all(X1, "\\( type:.*alias:|, length:.*| \\)")) |>
  separate(col = X1,
           into = c("field", "description"),
           sep = " ",
           extra = "merge") |>
  mutate(field = tolower(field))
  
```
STEPHANIE 12/10 - I've readded UHI since we may use it if the temperature data doesn't work out. ~~Also, the "raster" package/library also has its own select() function, so if we mean the dplyr select() function moving forward, we'll have to use dplyr::select().~~ Also moved this up before the temperature data since we need to load the geometry data to then use with the temp data below.

## Cleaning Temperature Data

Initial testing of raster data manipulation (to delete)
```{r}
#| eval: false

# Loading average July 2020 land surface temperature data
temp_test <- raster("data/MOD_LSTD_M_2020-07-01_rgb_3600x1800.FLOAT.TIFF")

# Pulling out the geometry from the landcover data
dc <- landcover |>
  dplyr::select(geometry, block_group) |>
  st_transform(crs = crs(temp_test)) # Aligning coordinate systems

# Aligning coordinate systems
heat <- extract(temp_test, dc, fun = mean)

# Creating temperature dataset
dc_temp <- bind_cols(heat, dc) |>
  rename(temp = ...1) 

dc_temp_sf <- st_as_sf(dc_temp) 

dc_temp |>
  count(temp)

# Visualizing temperature data
dc_temp_sf |>
  ggplot() +
  geom_sf(mapping = aes(fill = temp)) +
  scale_fill_gradient(
    'Temperature',
    low = 'blue',
    high = 'red'
  ) +
  labs(title = "DC Average July 2020 Temperature") +
  theme_minimal() 

# Exploring UHI variable
st_drop_geometry(landcover) |>
  count(uhi)

```
Stephanie 12/10 - Downloaded temperature data from NASA's Earth Observations: https://neo.gsfc.nasa.gov/view.php?datasetId=MOD_LSTD_M&date=2020-07-01

## Exploring Census Demographic Data

```{r}

# Load ACS 5-yr 2016-2020 data
variables <- load_variables(2020, "acs5") |>
  filter(geography == "block group")

```
STEPHANIE PRE-12/3
I (Stephanie) think we could use some or all of the following ACS data:
* B01003_001 - Total population
* B02001_002 through B02001_010 - Population for different racial groups
* B15003_002 through B15003_025 - Educational attainment of those 25 and over
* B19001_002 through B19001_017 - Household income in the past 12 months
* B25001_001 - Total # of housing units
* B25002_002 & B25002_003 - Total # of occupied or vacant units
* B25075_002 through B25075_027 - Total value of housing units

I'll only load a few below for analysis since we haven't agreed on the variables yet, but I want to be able to play around with some data. -Stephanie

JAMIE 12/3 - I like these variables! Here are some ideas to scale them and make them relatable across areas and years:
* B01003_001 - Total population
- Log population growth since the previous 5-yr ACS
- Population per square mile or other distance (density)
- Population per total # of housing units

* B02001_002 through B02001_010 - Population for different racial groups
- Same thoughts as above

* B15003_002 through B15003_025 - Educational attainment of those 25 and over
- Share of population with each level of educational attainment
- Population with each level of educational attainment per square mile, or other distance (density of educational attainment)
- Population with each level of educational attainment per total # of housing units

* B19001_002 through B19001_017 - Household income in the past 12 months
- We just need to put in terms of one year's dollars - such as 2020 dollars
- Maybe we can use a metric that standardizes this relative to the living wage in the area (using a source like the MIT living wage calculator)

* B25075_002 through B25075_027 - Total value of housing units
- Same thoughts as above, need to put in terms of one year's dollars

If these are of interest, I'm happy to pull the data and add the calculations.

MADELEINE 12/4:
I think all the variables listed above sound good. I'd perhaps add either
* B25064_001 - Median gross rent, or
* B25071_001 - Median gross rent as a percentage of household income

Thinking that these help provide more of a sense of what it actually costs to live in that neighborhood vs. just the value of property (though I also think value is important).

A couple questions:
- I'm not sure we need to convert to 2020 dollars since it seems like that may have already been done? If you look at the concept column for the B19001 vars, for instance, it says "in 2020 inflation-adjusted dollars".
- Is there a reason we are planning to use the bracketed variables instead of continuous? for instance, B19001_01 vs. 02 through 017

Stephanie 12/4
Remember we have to think about weights!



MADELEINE 12/12: I added the following variables: Population by race (B02001...), total continuous HH income (B19001_001E), median property value (B25077_001E), total property value (	
B25075_001E), median gross rent as % HH income (B25071_001E), total educational attainment (B15003_001E). Some notes/thoughts:

* We obviously don't need both the income categories and the continuous income - I just wanted to add in everything for now for data exploration. We can always drop the variables we're not using later downstream

* Also prob don't need both total and median property values - just wanted to look at both

* Also wondering if we should use median HH income instead of total?

* I believe the race categories I included should sum to the total population, but will test this

* I'm not sure what "total educational attainment" looks like - will do some testing there too. If it's hard to interpret or not in a useful format, we can use the categorical education variables (would probably want to consolidate them into fewer categories like HS or less, some college, BA+)

* It occurs to me we may need to choose baseline categories for any categorical variables we include and leave those out? Not sure if that is only a requirement for linear regression? 

## Loading Census demographic data via API

```{r}

# Secure Census API key (from .env file) for use in Census API call
load_dot_env()
credential <- Sys.getenv("census_api_key")

### I think since we're not using the tidycensus package to obtain the ACS data,
### we don't need this code
# census_api_key(credential, install = TRUE, overwrite = TRUE)

# Create url for API call
url <- str_glue(paste0("https://api.census.gov/data/2020/acs/acs5?get=",
             # Description of data point
             "NAME,",
             # TOTAL POPULATION ESTIMATE
             "B01003_001E,",
             # TOTAL POPULATION BY RACE - WHITE ALONE
             "B02001_002E,",
             # TOTAL POPULATION BY RACE - BLACK OR AFR AMER ALONE
             "B02001_003E,",
             # TOTAL POPULATION BY RACE - AMER IND AND AK NAT ALONE
             "B02001_004E,",
             # TOTAL POPULATION BY RACE - ASIAN ALONE
             "B02001_005E,",
             # TOTAL POPULATION BY RACE - NAT HAW OR PAC ISL ALONE
             "B02001_006E,",
             # TOTAL POPULATION BY RACE - OTHER ALONE + TWO OR MORE RACES
             "B02001_008E,",
             # TOTAL LESS THAN $10,000
             # HOUSEHOLD INCOME IN THE PAST 12 MONTHS
             "B19001_002E,",
             # TOTAL $10,000 - $14,999
             # HOUSEHOLD INCOME IN THE PAST 12 MONTHS
             "B19001_003E,",
             # TOTAL $15,000 - $19,999
             # HOUSEHOLD INCOME IN THE PAST 12 MONTHS   
             "B19001_004E,",
             # TOTAL $20,000 - $24,999
             # HOUSEHOLD INCOME IN THE PAST 12 MONTHS             
             "B19001_005E,",
             # TOTAL $25,000 - $29,999
             # HOUSEHOLD INCOME IN THE PAST 12 MONTHS
             "B19001_006E,",
             # TOTAL $30,000 - $34,999
             # HOUSEHOLD INCOME IN THE PAST 12 MONTHS      
             "B19001_007E,",
             # TOTAL $35,000 - $39,999
             # HOUSEHOLD INCOME IN THE PAST 12 MONTHS
             "B19001_008E,",
             # TOTAL $40,000 - $44,999
             # HOUSEHOLD INCOME IN THE PAST 12 MONTHS
             "B19001_009E,",
             # TOTAL $45,000 - $49,999
             # HOUSEHOLD INCOME IN THE PAST 12 MONTHS
             "B19001_010E,",
             # TOTAL $50,000 - $59,999
             # HOUSEHOLD INCOME IN THE PAST 12 MONTHS
             "B19001_011E,",
             # TOTAL $60,000 - $74,999
             # HOUSEHOLD INCOME IN THE PAST 12 MONTHS       
             "B19001_012E,",
             # TOTAL $75,000 - $99,999
             # HOUSEHOLD INCOME IN THE PAST 12 MONTHS
             "B19001_013E,",
             # TOTAL $100,000 - $124,999
             # HOUSEHOLD INCOME IN THE PAST 12 MONTHS
             "B19001_014E,",
             # TOTAL $125,000 - $149,999
             # HOUSEHOLD INCOME IN THE PAST 12 MONTHS
             "B19001_015E,",
             # TOTAL $150,000 - $199,999
             # HOUSEHOLD INCOME IN THE PAST 12 MONTHS
             "B19001_016E,",
             # TOTAL $200,000 or more
             # HOUSEHOLD INCOME IN THE PAST 12 MONTHS
             "B19001_017E,",
             # TOTAL CONTINUOUS
             # HOUSEHOLD INCOME IN THE PAST 12 MONTHS
             "B19001_001E,",
             # MEDIAN PROPERTY VALUE
             "B25077_001E,",
             # TOTAL PROPERTY VALUE
             "B25075_001E,",
             # MEDIAN GROSS RENT
             # AS A PERCENTAGE OF HOUSEHOLD INCOME IN THE PAST 12 MONTHS
             "B25071_001E,",
             # TOTAL EDUCATIONAL ATTAINMENT
             # FOR THE POPULATION 25 YEARS AND OLDER
             "B15003_001E",
             # Limit to block-group-level data for DC
             "&for=block%20group:*&for=tract:*&in=state:11&in=county:001"))

# Use url to request data from API
acs_json <- GET(url = url)

# Check call status
http_status(acs_json)

# Save API JSON response as text
acs_json <- content(acs_json, as = "text")

# Save JSON as character matrix
acs_matrix <- fromJSON(acs_json)

# Convert matrix to tibble
acs_data <- as_tibble(acs_matrix[2:nrow(acs_matrix), ],
                      .name_repair = "minimal")

# Add variable names to tibble
names(acs_data) <- acs_matrix[1, ] |>
  str_replace(" ", "_")

# Clean up data
acs_data <- acs_data |>
  rename(total_pop = B01003_001E,
         pop_race_white = B02001_002E,
         pop_race_black = B02001_003E,
         pop_race_amerind = B02001_004E,
         pop_race_asian = B02001_005E,
         pop_race_hi_pi = B02001_006E,
         pop_race_oth_mult = B02001_008E,
         nc_less_10000 = B19001_002E,
         inc_10000_14999 = B19001_003E,
         inc_15000_19999 = B19001_004E,
         inc_20000_24999 = B19001_005E,
         inc_25000_29999 = B19001_006E,
         inc_30000_34999 = B19001_007E,
         inc_35000_39999 = B19001_008E,
         inc_40000_44999 = B19001_009E,
         inc_45000_49999 = B19001_010E,
         inc_50000_59999 = B19001_011E,
         inc_60000_74999 = B19001_012E,
         inc_75000_99999 = B19001_013E,
         inc_100000_124999 = B19001_014E,
         inc_125000_149999 = B19001_015E,
         inc_150000_199999 = B19001_016E,
         inc_200000_more = B19001_017E,
         inc_continuous = B19001_001E,
         med_prop_val = B25077_001E,
         tot_prop_val = B25075_001E,
         med_rent_pct_inc = B25071_001E,
         educ_total = B15003_001E,
         block_group_temp = block_group) |>
  # Create block_group column to use for combining this with the other datasets
  mutate(block_group = paste(state,
                             county, 
                             tract, 
                             block_group_temp,
                             sep = "")) |>
  # Median property value and median rent as % HH income need some recoding
  # I'm replacing -666666's with 0. This might not be a complete solution,
  # but didn't want to introduce NA's into our data if not necessary
  mutate(
    med_prop_val = if_else(
      med_prop_val >= 1, med_prop_val, "0"),
    med_rent_pct_inc = if_else(
      med_rent_pct_inc >= 1, med_rent_pct_inc, "0")
    ) |>
  rename_all(tolower) |>
  relocate(block_group, .before = name)
                             
```


Exploration of some of the continuous variables
```{r}

# Income continuous
acs_data |>
  ggplot() +
  geom_histogram(aes(x = as.numeric(inc_continuous))
  )

# Total educational attainment
acs_data |>
  ggplot() +
  geom_histogram(aes(x = as.numeric(educ_total))
  )
# Still not sure how to interpret this one. Might be worth going back to the categories
```
## Stitching Together Final Dataset

Stephanie 12/11 - We'll have to change the bottom code due to using different temperature data
MA 12/12 - Changed this to just join acs_data and landcover - may need more edits
```{r}

#dataset_interim <- left_join(acs_data, st_drop_geometry(dc_heat), by = "block_group")
#dataset_final <- left_join(dataset_interim, landcover, by = "block_group")

## Checking to make sure we have all the variables
#colnames(dataset_final)

# MA: copied and then commented out the above; rewriting with just ACS + landcover
dataset_final <- left_join(acs_data, landcover, by = "block_group")
# Checking to make sure we have all the variables
colnames(dataset_final)

```

## Initial EDA
### DC Temperature Map

Stephanie 12/11 - We'll have to change the bottom code due to using different temperature data
MA 12/12 - Created new map using landcover 'uhi' variable for temperature, but only using 'landcover' as a dataset - need to figure out how to make 'dataset_final' work
```{r}

# MA: This just uses 'landcover'. I was getting errors trying to run the same code using 'dataset_final'
# even though it should have all the same geometry data. Not sure if I'm forgetting a step

landcover |> ggplot() +
  geom_sf(
    mapping = aes(fill = uhi),
    color = "white"
    ) +
    scale_fill_gradient(
    low = "#f7ef9d",
    high = "#be2b25"
    ) +
  labs(
    title = "Average evening temperature, 2018",
    fill = "Temperature (degrees F)"
  ) +
  theme_void()

```

# Supervised Machine Learning Applications

## Decision Trees

Stephanie 12/11 - We'll have to change the bottom code due to using different temperature data
Madeleine 12/12 - Updated this to work with UHI variable from landcover
Deciding the threshold for hot vs. not hot:
```{r}

# visualizing a cumulative histogram of counts of UHI values
dataset_final |>
  group_by(uhi) |>
  ggplot(aes(uhi)) +
  geom_histogram(aes(y = cumsum(..count..)))

# calculating frequency & cumulative frequency
heat_freq <- dataset_final |>
  count(uhi)
heat_freq$cumulative <- cumsum(heat_freq$n) 

heat_freq |>
  filter(
    cumulative >= 285,
    cumulative <= 286) |> head()

```
STEPHANIE PRE-12/3
Since there's 571 block groups, that means if we want to decide the heat threshold is where 50% of the data is above/below this line, then we'd want to pick the UHI value where cumulative = 285 or 286. The closest datapoint is UHI = 7.9 (Where cumulative = 268). I vote that we pick UHI <= 7.9 means not a heat island whereas UHI > 7.9 means it is a heat island.

MADELEINE 12/4
We might want to consider a higher threshold? I'm thinking it would be more meaningful to point out, say, the hottest 25% of block groups vs. the top 50%.

MADELEINE 12/12
New 50% threshold (UHI data from landcover; C to F conversion) is 90.1.

Implementing threshold:
```{r}

dataset_final <- dataset_final |>
  mutate(hotspot = if_else(uhi <= 90.1, "Hotspot", "Not Hotspot"))

dataset_dt <- dataset_final |>
  st_drop_geometry() |>
  select(-uhi, -geometry, -block_group, -name, -intptlat, -intptlon) 
#dropping uhi because that would be the main decision tree factor

```

### Running decision tree
STEPHANIE PRE-12/3
Note: We should do some more data cleaning on dataset_final before running the decision tree but it's getting late and I am tired, so I'm leaving it as is for now -Stephanie
```{r}

set.seed(20241202)

dt_split <- initial_split(data = dataset_dt, prop = 0.8)
dt_train <- training(x = dt_split) 
dt_test <- testing(x = dt_split)

dt_recipe <- recipe(formula = hotspot ~ ., data = dataset_dt) |>
  themis::step_downsample(hotspot) |> #I don't know if we need this or not...
  step_nzv(all_numeric_predictors())

dt_model <- decision_tree() |>
  set_engine(engine = "rpart") |>
  set_mode(mode = "classification")

dt_workflow <- workflow() |>
  add_recipe(dt_recipe) |>
  add_model(dt_model)
  
dt_fitting <- dt_workflow |>
  fit(data = dt_train)

rpart.plot::rpart.plot(x = dt_fitting$fit$fit$fit,
                       roundint = FALSE)

```
Stephanie 12/4
Looks like block group is the main determinant, which makes sense haha - should probably remove that column.

## Linear Regression
```{r}



```

## Random Forests
```{r}



```


## Sources

https://www.climatecentral.org/climate-matters/urban-heat-islands-2024

https://opendata.dc.gov/datasets/DCGIS::urban-tree-canopy-by-census-block-group-in-2020/about

Census ACS

